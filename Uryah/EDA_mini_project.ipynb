{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Welcome to your first EDA \\(Exploratory Data Analysis\\)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Our task at hand \\-\\- I hope you like penguins!\n",
    "\n",
    "For our mini project, we are going to use Pandas and Numpy to conduct a basic Exploratory Data Analysis on a penguins dataset. Specifically, we are looking at the <u>Palmer Archipelago \\(Antarctica\\) Penguins</u> dataset, which you can find here:  [https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins\\-raw.csv](https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins-raw.csv)\n",
    "\n",
    "Not sure what an exploratory data analysis is? You can google it! The best definition I found is below:\n",
    "\n",
    "_**Exploratory Data Analysis**_ **refers to the critical process of performing initial investigations on data so as to discover patterns, to spot anomalies, to test hypotheses and to check assumptions with the help of summary statistics and graphical representations.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Before anything else let's import our library for data analysis, pandas.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Loading in and understanding our data\n",
    "\n",
    "We need to read in our data. It is currently a .csv \\(comma\\-separated value\\) file, and we generally use the pd.read\\_csv\\(\\) function from pandas to read our data into a dataframe. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "penguins_dataframe = pd.read_csv(\"https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins-raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**TODO:** Can you run the .head\\(\\) and .tail\\(\\) function on our new dataframe? Can you print the name of all the columns in our dataframe? How about the number of rows?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Run head() on penguins_dataframe\n",
    "penguins_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Run tail() on penguins_dataframe\n",
    "penguins_dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Print the name of all the columns in our dataframe\n",
    "penguins_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Use google to find out how to print the number of rows in this dataset.\n",
    "import pandas as pd\n",
    "penguins_dataframe = pd.read_csv(\"https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/master/palmerpenguins/data/penguins-raw.csv\")\n",
    "penguins_dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Do your research\n",
    "\n",
    "What do the column names mean? At this point you should look up the meanings of any columns you don't know about and make some comments below. \n",
    "\n",
    "Typically at this point we would read up on the domain we are performing data analysis on. To do research on penguins you should probably get to know something about penguins!\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "What do these columns mean?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 3: Cleaning up our Data\n",
    "\n",
    "This data is a lot to take in. How do we know if we can even use this data? I see some weird columns and lots of N/A values.\n",
    "\n",
    "Let's talk through some functions to clean our data and see if it is salvagable. To start, we cannot use all of these columns. I'm thinking I want to get rid of \"studyName\" and \"Comments\" since they are not super useful for understanding the data relationships. I'll do that below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "#Make a list of what you want to drop\n",
    "columns_to_drop = ['studyName', 'Comments']\n",
    "\n",
    "#Drop the columns using drop()\n",
    "penguins_dataframe.drop(columns_to_drop, axis=1, inplace = True) #axis = 1 lets pandas know we are dropping columns, not rows.\n",
    "\n",
    "#Check that they are dropped\n",
    "penguins_dataframe.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**What does inplace mean?** This argument in the `drop()` function means we are changing the dataframe in place! If we had `inplace = False`, we would need to create a new dataframe like so: \n",
    "\n",
    "`new_penguins_dataframe = penguins_dataframe.drop(columns_to_drop, axis=1, inplace = False)`\n",
    "\n",
    "**TODO:** Can you drop the Sample Number, Individual ID, Delta 15 N \\(o/oo\\), and Delta 13 C \\(o/oo\\) columns using the example above?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Drop the Sample Number, Individual ID,  columns using the example above.\n",
    "columns_to_drop = [\"Sample Number\", \"Individual ID\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\"]\n",
    "\n",
    "\n",
    "#Drop the columns using drop()\n",
    "penguins_dataframe.drop(columns_to_drop, axis=1, inplace = True) #axis = 1 lets pandas know we are dropping columns, not rows.\n",
    "\n",
    "#Check that they are dropped\n",
    "penguins_dataframe.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Getting Rid of N/A's\n",
    "\n",
    "I see lots of N/A's, which we typically cannot visualize or use in machine learning.\n",
    "Now, I want to get rid of all the rows that have NA's in them. I'll show you how. **TODO:** Can you print the number of rows our dataframe has after I drop the NAs?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# This is a very convenient function to drop all rows that have N/A values!\n",
    "penguins_dataframe.dropna(inplace=True)\n",
    "penguins_dataframe.reset_index(drop=True, inplace=True) #Very good practice to reset how your rows are counted when you drop rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Print the number of rows our new dataframe has.\n",
    "11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exploring the Data\n",
    "\n",
    "Pandas has some amazing tools for exploring your data. Since this is a **mini** project, we will walk through only a few key features of pandas exploration. You can expect to do lots of research on your own to best explore, clean, and visualize your data for your project. \n",
    "\n",
    "First we will learn how to access certain columns of data and use conditions to get subsets of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# access a column using df[\"<COLUMN_NAME\"] or df.COLUMN_NAME\n",
    "penguins_dataframe[\"Species\"].head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "penguins_dataframe.Species.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "#You can also access multiple columns using double brackets (printing a \"list\" of columns)\n",
    "penguins_dataframe[[\"Species\",\"Region\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**TODO: Can you print the last five rows of the Island and Region columns?** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Print the last five rows of the Island and Region columns.\n",
    "penguins_dataframe[[\"Species\",\"Region\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<u>**Conditions in Pandas**</u>\n",
    "\n",
    "Pandas is also incredible for selecting subsets of columns that fit a certain condition. Check out the code below to get only the Adelie penguins.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "penguins_dataframe[penguins_dataframe[\"Species\"] == \"Adelie Penguin (Pygoscelis adeliae)\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Conditions in pandas work just like `if` statements in python. \n",
    "\n",
    "**TODO: Can you tell me which species of penguin can have a flipper length greater than or equal to 230 by using conditions in pandas?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Use pandas to find out which species of penguin can have a flipper length greater than or equal to 230\n",
    "penguins_dataframe[penguins_dataframe[\"Species\"] == \"Adelie Penguin (Pygoscelis adeliae)\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**TODO:** Take 5 minutes to explore the dataset on your own. There's some space for you to code below.\n",
    "\n",
    "Think of what you want to learn. Maybe what the smallest flipper size penguin is? How about the smallest culmen width? What is the largest penguin by mass?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Drop the Sample Number, Individual ID,  columns using the example above.\n",
    "columns_to_drop = [\"Sample Number\", \"Individual ID\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\"]\n",
    "\n",
    "\n",
    "#Drop the columns using drop()\n",
    "penguins_dataframe.drop(columns_to_drop, axis=1, inplace = True) #axis = 1 lets pandas know we are dropping columns, not rows.\n",
    "\n",
    "#Check that they are dropped\n",
    "penguins_dataframe.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Visualize on the Fly with Pandas\n",
    "\n",
    "Before we create mind\\-blowing visualizations, it is sometimes worth it to create quick visualizations to get ourselves oriented with the data and it's underlying patterns. \n",
    "\n",
    "I put a simple histogram below that helps me understand how the dataset is distributed. Notice that is is pretty hard to read and ugly, but it gets the job done for the data scientist. I now know that there are three species of penguin we are worried about, and that we have a lot more samples of the Adelie penguin than the Gentoo and Chinstrap \\(a good to know for machine learning\\). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Create a histogram of a column's data using the df.hist() function. I found it here: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html\n",
    "penguins_dataframe.hist(column=\"Culmen Length (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**TODO: Create a histogram of another column of your choice below.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Create a histogram of another column of your choice below.\n",
    "penguins_dataframe.hist(column=\"Flipper Length (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**TODO:** Now, let's have some fun. Can you create plots using the following functions?\n",
    "\n",
    "1. Scatter Plot: [https://pandas.pydata.org/pandas\\-docs/version/0.25.0/reference/api/pandas.DataFrame.plot.scatter.html](https://pandas.pydata.org/pandas-docs/version/0.25.0/reference/api/pandas.DataFrame.plot.scatter.html)\n",
    "2. Pie Plot: [https://pandas.pydata.org/docs/user\\_guide/visualization.html\\#visualization\\-pie](https://pandas.pydata.org/docs/user_guide/visualization.html#visualization-pie)\n",
    "\n",
    "Pro challenge: Add a title to each!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Create a scatter here\n",
    "penguins_dataframe.plot.scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "#Create a pie plot here - might look more like art than data science. Is a pie chart a good choice for the column?\n",
    "df = pd.DataFrame({'mass': [0.330, 4.87 , 5.97],\n",
    "                   'radius': [2439.7, 6051.8, 6378.1]},\n",
    "                  index=[\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\"])\n",
    "plot = df.plot.pie(y='mass', figsize=(5, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Creating Beautiful Visualizations with Plotly\n",
    "\n",
    "So far, it looks like a scatter plot might be our best bet! Now we want to make a beautiful scatter plot using `plotly.`Just like pandas and numpy, plotly is a module that lets us create beautiful visualizations in just a few lines of code. \n",
    "\n",
    "I'm only going to help with the import, so I need you to spend time on plotly's documentation in order to build the same scatter plot you did in the last section, but nicer. Maybe google \"Scatter plots in plotly python\" to start!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import plotly.express as px #importing plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**TODO:** Create a scatter plot using plotly. Please add a title here!\n",
    "\n",
    "Maybe google \"Scatter plots in plotly python\" to start!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Create a scatter plot\n",
    "penguins_dataframe.plotly.scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**TODO:** Let's make it look even better. Copy your function from above but add another argument to the function by setting the `color=\"Species\"`. Not sure what this means? Get to the scatter plots page on plotly and scroll down to the \"Setting size and color with column names\" section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Create the same scatter plot with color=\"Species\". Feeling crazy? Set a column name to the \"size\" argument as well!\n",
    "penguins_dataframe.plot.scatter\n",
    "color=\"Species\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Scatter Matrix:** I wanted to create a scatter plot for every possible numerical combination of 'Culmen Length \\(mm\\)', 'Culmen Depth \\(mm\\)', 'Flipper Length \\(mm\\)', and 'Body Mass \\(g\\)'. This could help me understand what is correlated and could mean a relationship between each other. The code to do so is below; are there any findings you can take away from this data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# My scatter matrix!\n",
    "numerical_penguins_df = penguins_dataframe[['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)',\n",
    "       'Body Mass (g)']]\n",
    "fig = px.scatter_matrix(numerical_penguins_df)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Putting the DA in EDA\n",
    "\n",
    "We now have explored our data some, and have built some beautiful visualizations to showcase patterns our data. But having a plot doesn't mean anything to someone who can't understand how to read plots.\n",
    "\n",
    "Below you can continue your analysis if you have hypotheses you'd like to explore with the penguins \\(i.e. is flipper length related to culmen depth? Which species has the largest culmen area?\\). After you are done, please write up some descriptions for your findings on this dataset. One question we answered earlier was _which species has the largest flipper length?_ You can start with you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Continue your analysis below -- try something new!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Continue your analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Thank you!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08210294964727e4010dccc398c44f22b92a2e77e2aceea574ad21eae77cd8e8"
  },
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3-ubuntu",
   "resource_dir": "/usr/local/share/jupyter/kernels/python3-ubuntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 4
}